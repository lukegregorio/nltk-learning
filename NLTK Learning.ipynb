{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85a273f-cd1a-46fc-b108-e38dd9e0967f",
   "metadata": {},
   "source": [
    "### Learning NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b2ff1-8aac-421f-93f3-2e3d3c7fac45",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32d19e4-967a-4661-927a-089c889caa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf129ef-2896-4662-8d70-2effdfd1a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download all the packages - take a minute or so - you will see a popup\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed04b83-75e7-420f-a3f9-d68de0123a3b",
   "metadata": {},
   "source": [
    "#### Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c7a32-01c4-48f6-ab3a-d8d22ba77695",
   "metadata": {},
   "source": [
    "Tokenising just means splitting up some body of text (eg by word or by sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ba61d-5526-4119-8463-2ce901a427fb",
   "metadata": {},
   "source": [
    "We use the package's splittings because it is better and more efficient than us making long arse regex - one advantage of nltk \n",
    "is that it can save us lots of time from regex and in pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73873156-8ceb-4dd3-8649-8be523bcf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cfd6ec-df02-4968-9c4a-7c4a343508c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'battle', 'over', 'abortion', 'rights', 'in', 'the', 'US', 'shifted', 'rapidly', 'to', 'Congress', 'and', 'the', 'midterm', 'elections', 'after', 'the', 'Supreme', 'Court', 'overturned', 'Roe', 'vs', 'Wade', '.', 'Conservative', 'states', 'began', 'to', 'implement', 'new', 'abortion', 'restrictions', 'across', 'the', 'country', 'in', 'the', 'wake', 'of', 'Friday', '’', 's', 'ruling', '.', 'Democrats', 'on', 'Capitol', 'Hill', 'and', 'running', 'for', 'national', 'office', 'called', 'for', 'abortion', 'rights', 'to', 'be', 'protected', 'through', 'legislation', ',', 'and', 'sought', 'to', 'depict', 'Republicans', 'as', 'dangerously', 'out', 'of', 'step', 'with', 'average', 'Americans', 'heading', 'into', 'the', 'November', 'vote', '.']\n",
      "['The battle over abortion rights in the US shifted rapidly to Congress and the midterm elections after the Supreme Court overturned Roe vs Wade.', 'Conservative states began to implement new abortion restrictions across the country in the wake of Friday’s ruling.', 'Democrats on Capitol Hill and running for national office called for abortion rights to be protected through legislation, and sought to depict Republicans as dangerously out of step with average Americans heading into the November vote.']\n"
     ]
    }
   ],
   "source": [
    "# set up body of text\n",
    "text = 'The battle over abortion rights in the US shifted rapidly to Congress and the midterm elections after the Supreme Court overturned Roe vs Wade. Conservative states began to implement new abortion restrictions across the country in the wake of Friday’s ruling. Democrats on Capitol Hill and running for national office called for abortion rights to be protected through legislation, and sought to depict Republicans as dangerously out of step with average Americans heading into the November vote.'\n",
    "\n",
    "# split into word\n",
    "print(word_tokenize(text))\n",
    "\n",
    "# split by sentence\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ed43d-4203-4a40-8e5d-1e891850021f",
   "metadata": {},
   "source": [
    "#### Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78115ab7-cb45-4ea2-9622-acaece6205b1",
   "metadata": {},
   "source": [
    "These are just commonly used but kinda less meaningful words in the english language we might want to exclude in analysis (eg'the','should' etc). In the jargon we might think of 'context words' and 'content words' - context words are built around other things, but dont give much info themselves. (nonetheless context might be useful to analyse writing styles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00fc4dbb-3659-48ed-94f4-e0637962416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# use the packages stopwords in english - note that lower case means only lower case stop words - take a set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# get text tokenized by words\n",
    "text_word = word_tokenize(text)\n",
    "\n",
    "# filter out stop words - casefold method ensures both cases are applied - so ensures upper case stop words are filtered out\n",
    "filtered_text_word = [i for i in text_word if i.casefold() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854112f-4b77-433e-af18-dacd4d08b345",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dea0ef-20f3-44ad-ba2e-2b4bf10566e5",
   "metadata": {},
   "source": [
    "We have 'playing' and 'play' - we want to think of these as having the same meaning/stem ('play'). We can use packages algorithms to stem down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6098edb0-7323-4a91-9d24-77d8a335ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# a modern stemming algorithm to use\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "to_stem = 'I played my play to the players in the audience. The musician was playing music.'\n",
    "to_stem = word_tokenize(to_stem)\n",
    "\n",
    "# call on our stemmer and then apply the stem method - notice play and playing get collapsed - though play is treated as the same too\n",
    "stemmed = [stemmer.stem(word) for word in to_stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5fbe9-b8a0-460f-bb0e-f6865c49a373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
